{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibrA138q0hCZ"
      },
      "source": [
        "# XGBoost Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq3Soe5hvIt-",
        "outputId": "fed27961-1cb5-414f-d286-d0120a024345"
      },
      "outputs": [],
      "source": [
        "# pip install xgboost\n",
        "# pip install --upgrade xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yrp1ffGEvrie",
        "outputId": "999856a2-d201-4717-da19-c5b585ac50f5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import mlflow\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "from hyperopt.pyll import scope\n",
        "\n",
        "\n",
        "# warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Read Data and Setup MLFLow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "O3i0nMU-cKl3",
        "outputId": "f88e7aef-5543-4dae-d768-a8be6fd5974c"
      },
      "outputs": [],
      "source": [
        "# read input data\n",
        "churn = pd.read_csv(\"../data/churn.txt\")\n",
        "pd.set_option(\"display.max_columns\", 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM2EGlQMvyq_",
        "outputId": "d0e1704d-9c39-42cb-f3c5-facaead0f4a6"
      },
      "outputs": [],
      "source": [
        "churn.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8rgKvZmfCPE"
      },
      "source": [
        "By modern standards, it’s a relatively small dataset, with only 5,000 records, where each record uses 21 attributes to describe the profile of a customer of an unknown US mobile operator. The attributes are:\n",
        "\n",
        "- `State`: the US state in which the customer resides, indicated by a two-letter abbreviation; for example, OH or NJ\n",
        "- `Account Length`: the number of days that this account has been active\n",
        "- `Area Code`: the three-digit area code of the corresponding customer’s phone number\n",
        "- `Phone`: the remaining seven-digit phone number\n",
        "- `Int’l Plan`: whether the customer has an international calling plan: yes/no\n",
        "- `VMail Plan`: whether the customer has a voice mail feature: yes/no\n",
        "- `VMail Message`: the average number of voice mail messages per month\n",
        "- `Day Mins`: the total number of calling minutes used during the day\n",
        "- `Day Calls`: the total number of calls placed during the day\n",
        "- `Day Charge`: the billed cost of daytime calls\n",
        "- `Eve Mins, Eve Calls, Eve Charge`: the billed cost for calls placed during the evening\n",
        "- `Night Mins`, `Night Calls`, `Night Charge`: the billed cost for calls placed during nighttime\n",
        "- `Intl Mins`, `Intl Calls`, `Intl Charge`: the billed cost for international calls\n",
        "- `CustServ Calls`: the number of calls placed to Customer Service\n",
        "- `Churn?`: whether the customer left the service: true/false\n",
        "\n",
        "The last attribute, `Churn?`, is known as the target attribute: the attribute that we want the ML model to predict.  Because the target attribute is binary, our model will be performing binary prediction, also known as binary classification.\n",
        "\n",
        "Let's begin exploring the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zPIHetwbfMcu",
        "outputId": "0627a9c6-e601-446e-cc84-ce37677f8205"
      },
      "outputs": [],
      "source": [
        "# Frequency tables for each categorical feature\n",
        "for column in churn.select_dtypes(include=[\"object\"]).columns:\n",
        "    display(pd.crosstab(index=churn[column], columns=\"% observations\", normalize=\"columns\"))\n",
        "\n",
        "# Histograms for each numeric features\n",
        "display(churn.describe())\n",
        "%matplotlib inline\n",
        "hist = churn.hist(bins=30, sharey=True, figsize=(10, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zkc9dclffLL"
      },
      "source": [
        "We can see immediately that:\n",
        "- `State` appears to be quite evenly distributed.\n",
        "- `Phone` takes on too many unique values to be of any practical use.  It's possible that parsing out the prefix could have some value, but without more context on how these are allocated, we should avoid using it.\n",
        "- Most of the numeric features are surprisingly nicely distributed, with many showing bell-like `gaussianity`.  `VMail Message` is a notable exception (and `Area Code` showing up as a feature we should convert to non-numeric)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6u-TdgPfp5i"
      },
      "outputs": [],
      "source": [
        "churn = churn.drop(\"Phone\", axis=1)\n",
        "churn[\"Area Code\"] = churn[\"Area Code\"].astype(object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ev6-PPQfsl0"
      },
      "source": [
        "\n",
        "Next let's look at the relationship between each of the features and our target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P-AZZs7Qftt9",
        "outputId": "ed6e955e-c82d-4dc7-a79c-a28918d631e8"
      },
      "outputs": [],
      "source": [
        "for column in churn.select_dtypes(include=[\"object\"]).columns:\n",
        "    if column != \"Churn?\":\n",
        "        display(pd.crosstab(index=churn[column], columns=churn[\"Churn?\"], normalize=\"columns\"))\n",
        "\n",
        "for column in churn.select_dtypes(exclude=[\"object\"]).columns:\n",
        "    print(column)\n",
        "    hist = churn[[column, \"Churn?\"]].hist(by=\"Churn?\", bins=30)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQZeMsMof10a"
      },
      "source": [
        "We see several features that essentially have 100% correlation with one another.  Including these feature pairs in some machine learning algorithms can create catastrophic problems, while in others it will only introduce minor redundancy and bias.  Let's remove one feature from each of the highly correlated pairs: `Day Charge` from the pair with `Day Mins`, `Night Charge` from the pair with `Night Mins`, `Intl Charge` from the pair with `Intl Mins`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWEKXwPFf3Q-"
      },
      "outputs": [],
      "source": [
        "churn = churn.drop([\"Day Charge\", \"Eve Charge\", \"Night Charge\", \"Intl Charge\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "izwxhGq9ge7y",
        "outputId": "9ee66839-ff8e-4f5f-f166-ab9f99c74fb5"
      },
      "outputs": [],
      "source": [
        "churn.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5CKaboRwCFh"
      },
      "outputs": [],
      "source": [
        "# Extract feature and target arrays\n",
        "X, y = churn.drop('Churn?', axis=1), churn[['Churn?']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wsbzWFnwP0l"
      },
      "outputs": [],
      "source": [
        "# Extract text features\n",
        "cats = X.select_dtypes(exclude=np.number).columns.tolist()\n",
        "\n",
        "# Convert to Pandas category\n",
        "for col in cats:\n",
        "   X[col] = X[col].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XGk2kA-wU95",
        "outputId": "76fe4d06-558a-42e7-95ee-714e1f8b332e"
      },
      "outputs": [],
      "source": [
        "X.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5-6ceVdg8KV"
      },
      "outputs": [],
      "source": [
        "y['Churn?'] = y['Churn?'].replace({'True.': 1, 'False.': 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVb114gRrmYq",
        "outputId": "e4081dd0-3a64-4559-cc36-47159b24e3a3"
      },
      "outputs": [],
      "source": [
        "y.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Gp5-INXwfwO"
      },
      "outputs": [],
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpM0nK07mLPg"
      },
      "outputs": [],
      "source": [
        "model = XGBClassifier(eval_metric='mlogloss', tree_method=\"hist\", enable_categorical=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "mQWsj4w8mZIc",
        "outputId": "d4613372-c352-477a-d4b4-b98d8af60b35"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHOFH-9TvmXl"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXO1A29rvvIO",
        "outputId": "a74a5d9b-ba0e-4584-c949-535f03476c14"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Using DMatrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test, enable_categorical=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "params = model.get_params()\n",
        "print(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # specify parameters via map\n",
        "# params = {'max_depth': None, 'eval_metric' : 'mlogloss', 'tree_method' : \"hist\", 'eta':1, 'objective':'binary:logistic'}\n",
        "# num_round = 2\n",
        "\n",
        "params = model.get_params()\n",
        "booster = xgb.train(\n",
        "    params=params,\n",
        "    dtrain=dtrain\n",
        ")\n",
        "\n",
        "\n",
        "# booster = xgb.train(\n",
        "#     params=params,\n",
        "#     dtrain=dtrain,\n",
        "#     num_boost_round=1000,\n",
        "#     evals=[(dtest,\"test\")],\n",
        "#     early_stopping_rounds=50\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# make prediction\n",
        "y_pred_prob = booster.predict(dtest)\n",
        "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the loss as the negative value of accuracy for minimization\n",
        "loss = -accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# specify parameters via map\n",
        "params = {'max_depth': None, 'eval_metric' : 'mlogloss', 'tree_method' : \"hist\", 'eta':1, 'objective':'binary:logistic'}\n",
        "num_round = 2\n",
        "\n",
        "# train model \n",
        "def objective(params):\n",
        "    \n",
        "    with mlflow.start_run():\n",
        "\n",
        "        mlflow.set_tag(\"model\", \"xgboost\")\n",
        "        mlflow.log_params(params)\n",
        "        booster = xgb.train(\n",
        "            params=params,\n",
        "            dtrain=dtrain,\n",
        "            num_boost_round=1000,\n",
        "            evals=[(dtest,\"test\")],\n",
        "            early_stopping_rounds=50\n",
        "        )\n",
        "\n",
        "        # make prediction\n",
        "        y_pred_prob = booster.predict(dtest)\n",
        "        y_pred = (y_pred_prob >= 0.5).astype(int)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "        mlflow.autolog()\n",
        "\n",
        "        # Define the loss as the negative value of accuracy for minimization\n",
        "        loss = -accuracy\n",
        "\n",
        "        return {'loss': loss, 'status': STATUS_OK}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "search_space = {\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
        "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
        "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
        "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
        "    'objective': 'binary:logistic',\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "best_result = fmin(\n",
        "    fn=objective,\n",
        "    space=search_space,\n",
        "    algo=tpe.suggest,\n",
        "    max_evals=50,\n",
        "    trials=Trials()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Selecting the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with mlflow.start_run():\n",
        "\n",
        "best_params = {\n",
        "    'learning_rate'\t: 0.2611886716276454,\n",
        "    'max_depth' : 39,\n",
        "    'min_child_weight' : 4.490391995734931,\n",
        "    'objective' : 'binary:logistic',\n",
        "    'reg_alpha' : 0.044567672488398144,\n",
        "    'reg_lambda' : 0.11968534468462336,\n",
        "    'seed' : 42\n",
        "}\n",
        "\n",
        "mlflow.log_params(best_params)\n",
        "\n",
        "booster = xgb.train(\n",
        "    params=best_params,\n",
        "    dtrain=dtrain,\n",
        "    num_boost_round=1000,\n",
        "    evals=[(dtest,\"test\")],\n",
        "    early_stopping_rounds=50\n",
        ")\n",
        "\n",
        "# make prediction\n",
        "y_pred_prob = booster.predict(dtest)\n",
        "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the loss as the negative value of accuracy for minimization\n",
        "loss = -accuracy\n",
        "\n",
        "   \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
